{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b74cedc-a25b-45dd-beb3-5b4987a9611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U einops datasets matplotlib tqdm\n",
    "\n",
    "import math\n",
    "from inspect import isfunction\n",
    "from functools import partial\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from einops import rearrange, reduce\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "import torch\n",
    "from torch import nn, einsum\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c352acc8-1ca0-4a05-92a7-05fe927cdf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the helper functions\n",
    "\n",
    "def defaultValue(value, default_value):\n",
    "    if isNone(value):\n",
    "        return default_value\n",
    "    return default_value() if isfunction(default_value) else default_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52150f8c-55fb-4577-a0d1-2247e1177265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network helper components.\n",
    "\n",
    "# Residual net layer.\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, activation_fn):\n",
    "        super().__init__()\n",
    "        self.activation_fn = activation_fn\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        return self.activation_fn(x, *args, **kwargs) + x\n",
    "\n",
    "# Conv upsampling layer, it upsamples the image by scale of 2 (twice).\n",
    "def Upsample(dim_in: int, dim_out=None):\n",
    "    return nn.Sequential(\n",
    "        nn.Upsample(scale_factor=2, mode=\"nearest\"),\n",
    "        nn.Conv2d(dim_in, default(dim_out, dim_in), kernel_size=3, padding=1),\n",
    "    )\n",
    "\n",
    "# Conv downsampling layer, it downsamples the image by half.\n",
    "def Downsample(dim_in: int, dim_out=None):\n",
    "    # No More Strided Convolutions or Pooling\n",
    "    return nn.Sequential(\n",
    "        # Split each image into 4 smaller images, and stack all four sub-images into\n",
    "        # the channels.\n",
    "        Rearrange(\"b c (h p1) (w p2) -> b (c p1 p2) h w\", p1=2, p2=2),\n",
    "        # Use the conv to sequeeze the dim as output one.\n",
    "        nn.Conv2d(dim * 4, default(dim_out, dim_in), 1),\n",
    "    )\n",
    "\n",
    "# Positional embedding layer.\n",
    "# We use the positional embedding to encode the timestamp t.\n",
    "# Here the timestamp means the t in the diffusion process.\n",
    "class SinusoidalPositionEmbeddings(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    # The time has dim: [B, 1], here 1 mean the correpsonding timestamp for that img.\n",
    "    def forward(self, time: torch.Tensor):\n",
    "        device = time.device\n",
    "        half_dim = self.dim // 2\n",
    "        embeddings = math.log(10000) / (half_dim - 1)\n",
    "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
    "        embeddings = time[:, None] * embeddings[None, :]\n",
    "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
    "        return embeddings\n",
    "\n",
    "# Assemble the CNN layers\n",
    "class WeightStandardizedConv2d(nn.Conv2d):\n",
    "    \"\"\"\n",
    "    https://arxiv.org/abs/1903.10520\n",
    "    weight standardization purportedly works synergistically with group normalization\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        eps = 1e-5 if x.dtype == torch.float32 else 1e-3\n",
    "\n",
    "        weight = self.weight\n",
    "        mean = reduce(weight, \"o ... -> o 1 1 1\", \"mean\")\n",
    "        var = reduce(weight, \"o ... -> o 1 1 1\", partial(torch.var, unbiased=False))\n",
    "        normalized_weight = (weight - mean) / (var + eps).rsqrt()\n",
    "        return F.conv2d(\n",
    "            x,\n",
    "            normalized_weight,\n",
    "            self.bias,\n",
    "            self.stride,\n",
    "            self.padding,\n",
    "            self.dilation,\n",
    "            self.groups,\n",
    "        )\n",
    "\n",
    "\n",
    "# This is a general CNN block which has group norm and SiLU.\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, dim, dim_out, groups=8):\n",
    "        super().__init__()\n",
    "        self.proj = WeightStandardizedConv2d(dim, dim_out, 3, padding=1)\n",
    "        self.norm = nn.GroupNorm(groups, dim_out)\n",
    "        self.act = nn.SiLU()\n",
    "\n",
    "    def forward(self, x, scale_shift=None):\n",
    "        x = self.proj(x)\n",
    "        x = self.norm(x)\n",
    "\n",
    "        if scale_shift is not None:\n",
    "            scale, shift = scale_shift\n",
    "            x = x * (scale + 1) + shift\n",
    "\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "    \"\"\"https://arxiv.org/abs/1512.03385\"\"\"\n",
    "\n",
    "    def __init__(self, dim, dim_out, *, time_emb_dim=None, groups=8):\n",
    "        super().__init__()\n",
    "        # Applys a MLP to encode the time embeddings (i.e. SinusoidalPosition).\n",
    "        self.mlp = (\n",
    "            nn.Sequential(nn.SiLU(), nn.Linear(time_emb_dim, dim_out * 2))\n",
    "            if time_emb_dim is not None\n",
    "            else None\n",
    "        )\n",
    "\n",
    "        self.block1 = Block(dim, dim_out, groups=groups)\n",
    "        self.block2 = Block(dim_out, dim_out, groups=groups)\n",
    "        self.res_conv = nn.Conv2d(dim, dim_out, 1) if dim != dim_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x, time_emb=None):\n",
    "        scale_shift = None\n",
    "        if self.mlp is not None and time_emb is not None:\n",
    "            time_emb = self.mlp(time_emb)\n",
    "            time_emb = rearrange(time_emb, \"b c -> b c 1 1\")\n",
    "            # Split the time embeddings into two tensors.\n",
    "            # One tensor is added as shift and another one is multiple as scale.\n",
    "            scale_shift = time_emb.chunk(2, dim=1)\n",
    "\n",
    "        h = self.block1(x, scale_shift=scale_shift)\n",
    "        h = self.block2(h)\n",
    "        return h + self.res_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baf6b5b-dfa2-4ce1-b871-c6502f0c03b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 10\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
